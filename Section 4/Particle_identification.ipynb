{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Acknowledgments\n",
    "\n",
    "## For PID data\n",
    "\n",
    " - [Mikhail Hushchyn](https://www.hse.ru/org/persons/213369348)\n",
    "\n",
    "## For SparseVD code\n",
    "\n",
    " - [Arsenii Ashukha](https://www.hse.ru/en/org/persons/204848606) from BayesLab for making code public: \n",
    "     - https://github.com/senya-ashukha/sparse-vd-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# About PID\n",
    "\n",
    "There are six particle types: electron, proton, muon, kaon, pion and ghost. Ghost is a particle with other type than the first five or a detector noise. \n",
    "\n",
    "Different particle types remain different responses in the detector systems or subdetectors. Thre are five systems: tracking system, ring imaging Cherenkov detector (RICH), electromagnetic and hadron calorimeters, and muon system.\n",
    "\n",
    "![pid](pic/pid.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If you not on cocalc use these lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# !wget --no-check-certificate \"https://onedrive.live.com/download?cid=D058F2D9E01D1496&resid=D058F2D9E01D1496%21107&authkey=AF7V2Rm2NTg2iDk\" -O \"training.csv.gz\"\n",
    "# training_file = './training.csv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If you on cocalc, use this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "training_file = '~/share/pid_sparse/training.csv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## All necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (0.8.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import numpy\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from logger import Logger\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "label_class_correspondence = {'Electron': 0, 'Ghost': 1, 'Kaon': 2, 'Muon': 3, 'Pion': 4, 'Proton': 5}\n",
    "class_label_correspondence = {0: 'Electron', 1: 'Ghost', 2: 'Kaon', 3: 'Muon', 4: 'Pion', 5: 'Proton'}\n",
    "\n",
    "\n",
    "def get_class_ids(labels):\n",
    "    \"\"\"\n",
    "    Convert particle type names into class ids.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    labels : array_like\n",
    "        Array of particle type names ['Electron', 'Muon', ...].\n",
    "\n",
    "    Return:\n",
    "    -------\n",
    "    class ids : array_like\n",
    "        Array of class ids [1, 0, 3, ...].\n",
    "    \"\"\"\n",
    "    return np.array([label_class_correspondence[alabel] for alabel in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul 25 16:27:01 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.126.02   Driver Version: 418.126.02   CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           Off  | 00000001:00:00.0 Off |                    0 |\r\n",
      "| N/A   51C    P0    69W / 149W |   2090MiB / 11441MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla K80           Off  | 00000002:00:00.0 Off |                    0 |\r\n",
      "| N/A   62C    P0    60W / 149W |     82MiB / 11441MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla K80           Off  | 00000003:00:00.0 Off |                    0 |\r\n",
      "| N/A   61C    P0    59W / 149W |    423MiB / 11441MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Tesla K80           Off  | 00000004:00:00.0 Off |                    0 |\r\n",
      "| N/A   49C    P0    73W / 149W |     82MiB / 11441MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "device = torch.device('cuda:3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load data\n",
    "\n",
    "Load data used to train classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Read training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrackP</th>\n",
       "      <th>TrackNDoFSubdetector2</th>\n",
       "      <th>BremDLLbeElectron</th>\n",
       "      <th>MuonLooseFlag</th>\n",
       "      <th>FlagSpd</th>\n",
       "      <th>SpdE</th>\n",
       "      <th>EcalDLLbeElectron</th>\n",
       "      <th>DLLmuon</th>\n",
       "      <th>RICHpFlagElectron</th>\n",
       "      <th>EcalDLLbeMuon</th>\n",
       "      <th>...</th>\n",
       "      <th>TrackNDoF</th>\n",
       "      <th>RICHpFlagMuon</th>\n",
       "      <th>RICH_DLLbeKaon</th>\n",
       "      <th>RICH_DLLbeElectron</th>\n",
       "      <th>HcalE</th>\n",
       "      <th>MuonFlag</th>\n",
       "      <th>FlagMuon</th>\n",
       "      <th>PrsE</th>\n",
       "      <th>RICH_DLLbeMuon</th>\n",
       "      <th>RICH_DLLbeProton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74791.156263</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.232275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-2.505719</td>\n",
       "      <td>6.604153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.929960</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.213300</td>\n",
       "      <td>-0.280200</td>\n",
       "      <td>5586.589846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.422315</td>\n",
       "      <td>-2.081143e-07</td>\n",
       "      <td>-24.824400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2738.489989</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.357748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.864351</td>\n",
       "      <td>0.263651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.061959</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.324317</td>\n",
       "      <td>1.707283</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.334935</td>\n",
       "      <td>2.771583e+00</td>\n",
       "      <td>-0.648017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2161.409908</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15277.730490</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.638984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-2.533918</td>\n",
       "      <td>-8.724949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.253981</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-35.202221</td>\n",
       "      <td>-14.742319</td>\n",
       "      <td>4482.803707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.194175</td>\n",
       "      <td>-3.070819e+00</td>\n",
       "      <td>-29.291519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7563.700195</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-0.638962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-2.087146</td>\n",
       "      <td>-7.060422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.995816</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.084287</td>\n",
       "      <td>-10.272412</td>\n",
       "      <td>5107.554680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-5.373712e+00</td>\n",
       "      <td>23.653087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TrackP  TrackNDoFSubdetector2  BremDLLbeElectron  MuonLooseFlag  \\\n",
       "0  74791.156263                   15.0           0.232275            1.0   \n",
       "1   2738.489989                   15.0          -0.357748            0.0   \n",
       "2   2161.409908                   17.0        -999.000000            0.0   \n",
       "3  15277.730490                   20.0          -0.638984            0.0   \n",
       "4   7563.700195                   19.0          -0.638962            0.0   \n",
       "\n",
       "   FlagSpd   SpdE  EcalDLLbeElectron     DLLmuon  RICHpFlagElectron  \\\n",
       "0      1.0    3.2          -2.505719    6.604153                1.0   \n",
       "1      1.0    3.2           1.864351    0.263651                1.0   \n",
       "2      0.0 -999.0        -999.000000 -999.000000                0.0   \n",
       "3      1.0    3.2          -2.533918   -8.724949                1.0   \n",
       "4      1.0    3.2          -2.087146   -7.060422                1.0   \n",
       "\n",
       "   EcalDLLbeMuon  ...  TrackNDoF  RICHpFlagMuon  RICH_DLLbeKaon  \\\n",
       "0       1.929960  ...       28.0            1.0       -7.213300   \n",
       "1      -2.061959  ...       32.0            1.0       -0.324317   \n",
       "2    -999.000000  ...       27.0            0.0     -999.000000   \n",
       "3      -3.253981  ...       36.0            1.0      -35.202221   \n",
       "4      -0.995816  ...       33.0            1.0       25.084287   \n",
       "\n",
       "   RICH_DLLbeElectron        HcalE  MuonFlag  FlagMuon        PrsE  \\\n",
       "0           -0.280200  5586.589846       1.0       1.0   10.422315   \n",
       "1            1.707283    -0.000007       0.0       1.0   43.334935   \n",
       "2         -999.000000  -999.000000       0.0       0.0 -999.000000   \n",
       "3          -14.742319  4482.803707       0.0       1.0    2.194175   \n",
       "4          -10.272412  5107.554680       0.0       1.0    0.000015   \n",
       "\n",
       "   RICH_DLLbeMuon  RICH_DLLbeProton  \n",
       "0   -2.081143e-07        -24.824400  \n",
       "1    2.771583e+00         -0.648017  \n",
       "2   -9.990000e+02       -999.000000  \n",
       "3   -3.070819e+00        -29.291519  \n",
       "4   -5.373712e+00         23.653087  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv(training_file)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### List of columns in the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here, **Spd** stands for Scintillating Pad Detector, **Prs** - Preshower, **Ecal** - electromagnetic calorimeter, **Hcal** - hadronic calorimeter, **Brem** denotes traces of the particles that were deflected by detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- ID - id value for tracks (presents only in the test file for the submitting purposes)\n",
    "- Label - string valued observable denoting particle types. Can take values \"Electron\", \"Muon\", \"Kaon\", \"Proton\", \"Pion\" and \"Ghost\". This column is absent in the test file.\n",
    "- FlagSpd - flag (0 or 1), if reconstructed track passes through Spd\n",
    "- FlagPrs - flag (0 or 1), if reconstructed track passes through Prs\n",
    "- FlagBrem - flag (0 or 1), if reconstructed track passes through Brem\n",
    "- FlagEcal - flag (0 or 1), if reconstructed track passes through Ecal\n",
    "- FlagHcal - flag (0 or 1), if reconstructed track passes through Hcal\n",
    "- FlagRICH1 - flag (0 or 1), if reconstructed track passes through the first RICH detector\n",
    "- FlagRICH2 - flag (0 or 1), if reconstructed track passes through the second RICH detector\n",
    "- FlagMuon - flag (0 or 1), if reconstructed track passes through muon stations (Muon)\n",
    "- SpdE - energy deposit associated to the track in the Spd\n",
    "- PrsE - energy deposit associated to the track in the Prs\n",
    "- EcalE - energy deposit associated to the track in the Hcal\n",
    "- HcalE - energy deposit associated to the track in the Hcal\n",
    "- PrsDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Prs\n",
    "- BremDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Brem\n",
    "- TrackP - particle momentum\n",
    "- TrackPt - particle transverse momentum\n",
    "- TrackNDoFSubdetector1  - number of degrees of freedom for track fit using hits in the tracking sub-detector1\n",
    "- TrackQualitySubdetector1 - chi2 quality of the track fit using hits in the tracking sub-detector1\n",
    "- TrackNDoFSubdetector2 - number of degrees of freedom for track fit using hits in the tracking sub-detector2\n",
    "- TrackQualitySubdetector2 - chi2 quality of the track fit using hits in the  tracking sub-detector2\n",
    "- TrackNDoF - number of degrees of freedom for track fit using hits in all tracking sub-detectors\n",
    "- TrackQualityPerNDoF - chi2 quality of the track fit per degree of freedom\n",
    "- TrackDistanceToZ - distance between track and z-axis (beam axis)\n",
    "- Calo2dFitQuality - quality of the 2d fit of the clusters in the calorimeter \n",
    "- Calo3dFitQuality - quality of the 3d fit in the calorimeter with assumption that particle was electron\n",
    "- EcalDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Ecal\n",
    "- EcalDLLbeMuon - delta log-likelihood for a particle candidate to be muon using information from Ecal\n",
    "- EcalShowerLongitudinalParameter - longitudinal parameter of Ecal shower\n",
    "- HcalDLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from Hcal\n",
    "- HcalDLLbeMuon - delta log-likelihood for a particle candidate to be using information from Hcal\n",
    "- RICHpFlagElectron - flag (0 or 1) if momentum is greater than threshold for electrons to produce Cherenkov light\n",
    "- RICHpFlagProton - flag (0 or 1) if momentum is greater than threshold for protons to produce Cherenkov light\n",
    "- RICHpFlagPion - flag (0 or 1) if momentum is greater than threshold for pions to produce Cherenkov light\n",
    "- RICHpFlagKaon - flag (0 or 1) if momentum is greater than threshold for kaons to produce Cherenkov light\n",
    "- RICHpFlagMuon - flag (0 or 1) if momentum is greater than threshold for muons to produce Cherenkov light\n",
    "- RICH_DLLbeBCK  - delta log-likelihood for a particle candidate to be background using information from RICH\n",
    "- RICH_DLLbeKaon - delta log-likelihood for a particle candidate to be kaon using information from RICH\n",
    "- RICH_DLLbeElectron - delta log-likelihood for a particle candidate to be electron using information from RICH\n",
    "- RICH_DLLbeMuon - delta log-likelihood for a particle candidate to be muon using information from RICH\n",
    "- RICH_DLLbeProton - delta log-likelihood for a particle candidate to be proton using information from RICH\n",
    "- MuonFlag - muon flag (is this track muon) which is determined from muon stations\n",
    "- MuonLooseFlag muon flag (is this track muon) which is determined from muon stations using looser criteria\n",
    "- MuonLLbeBCK - log-likelihood for a particle candidate to be not muon using information from muon stations\n",
    "- MuonLLbeMuon - log-likelihood for a particle candidate to be muon using information from muon stations\n",
    "- DLLelectron - delta log-likelihood for a particle candidate to be electron using information from all subdetectors\n",
    "- DLLmuon - delta log-likelihood for a particle candidate to be muon using information from all subdetectors\n",
    "- DLLkaon - delta log-likelihood for a particle candidate to be kaon using information from all subdetectors\n",
    "- DLLproton - delta log-likelihood for a particle candidate to be proton using information from all subdetectors\n",
    "- GhostProbability - probability for a particle candidate to be ghost track. This variable is an output of classification model used in the tracking algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Delta log-likelihood in the features descriptions means the difference between log-likelihood for the mass hypothesis that a given track is left by some particle (for example, electron) and log-likelihood for the mass hypothesis that a given track is left by a pion (so, DLLpion = 0 and thus we don't have these columns). This is done since most tracks (~80%) are left by pions and in practice we actually need to discriminate other particles from pions. In other words, the null hypothesis is that particle is a pion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Look at the labels set\n",
    "\n",
    "The training data contains six classes. Each class corresponds to a particle type. Your task is to predict type of a particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Electron', 'Ghost', 'Kaon', 'Muon', 'Pion', 'Proton'}"
      ]
     },
     "execution_count": 14,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Convert the particle types into class numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 15,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'] = get_class_ids(data.Label.values)\n",
    "set(data.Class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Define training features\n",
    "\n",
    "The following set of features describe particle responses in the detector systems:\n",
    "\n",
    "![features](pic/features.jpeg)\n",
    "\n",
    "Also there are several combined features. The full list is following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "features = list(set(data.columns) - {'Label', 'Class'})\n",
    "features = sorted(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Divide training data into 2 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "training_data, validation_data = train_test_split(data, random_state=11, train_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 1080000)"
      ]
     },
     "execution_count": 18,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data), len(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Torch Neural Network\n",
    "\n",
    "On this step your task is to train **Torch** NN classifier to provide lower **log loss** value and lower number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from sparse_model import SparseNet\n",
    "from sparse_vd import SGVLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "model = SparseNet(threshold=0.001, input_dim=len(features), device=device).to(device)\n",
    "optimizer = torch.optim.Adam(lr=1e-3, params=model.parameters()) # optimizer\n",
    "\n",
    "fmt = {'tr_los': '3.1e', 'te_loss': '3.1e', 'sp_0': '.3f', 'sp_1': '.3f', 'sp_2': '.3f', 'lr': '3.1e', 'kl': '.2f'}\n",
    "logger = Logger('sparse_vd', fmt=fmt)\n",
    "\n",
    "sgvlb = SGVLB(model, len(training_data[features].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# train dataloader\n",
    "tensor_x = torch.Tensor(training_data[features].values) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(training_data.Class.values).long()\n",
    "\n",
    "train_dataset = TensorDataset(tensor_x, tensor_y) # create your datset\n",
    "train_loader = DataLoader(train_dataset, batch_size=256) # create your dataloader\n",
    "\n",
    "# validation dataloader\n",
    "tensor_x = torch.Tensor(training_data[features].values) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(training_data.Class.values).long()\n",
    "val_dataset = TensorDataset(tensor_x, tensor_y) # create your datset\n",
    "val_loader = DataLoader(val_dataset, batch_size=256) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "nllloss = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2612428164431282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    kl    tr_los    tr_acc    te_loss    te_acc    te_nll    sp_0    sp_1    sp_2\n",
      "-------  ----  --------  --------  ---------  --------  --------  ------  ------  ------\n",
      "      1  0.00   7.5e+02      39.8    5.9e+02      45.1       1.3   0.852   0.771   0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r100%|██████████| 1/1 [00:07<00:00,  7.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r100%|██████████| 1/1 [00:07<00:00,  7.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "kl_weight = 0.0\n",
    "epochs = 1\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0 \n",
    "    logger.add_scalar(epoch, 'kl', kl_weight)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        pred = output.data.max(1)[1] \n",
    "        loss = sgvlb(output, target, kl_weight)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += float(loss) \n",
    "        train_acc += np.sum(pred.cpu().numpy() == target.data.cpu().numpy())\n",
    "        \n",
    "    logger.add_scalar(epoch, 'tr_los', train_loss / len(train_loader.dataset))\n",
    "    logger.add_scalar(epoch, 'tr_acc', train_acc / len(train_loader.dataset) * 100)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "    test_nll = 0\n",
    "    for batch_idx, (data, target) in enumerate(val_loader):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        \n",
    "        test_loss += float(sgvlb(output, target, kl_weight))\n",
    "        test_nll += nllloss(output, target).item()\n",
    "        pred = output.data.max(1)[1] \n",
    "        test_acc += np.sum(pred.cpu().numpy() == target.data.cpu().numpy())\n",
    "        \n",
    "    logger.add_scalar(epoch, 'te_loss', test_loss / len(val_loader.dataset))\n",
    "    logger.add_scalar(epoch, 'te_acc', test_acc / len(val_loader.dataset) * 100)\n",
    "    logger.add_scalar(epoch, 'te_nll', test_nll / len(val_loader))\n",
    "    print(test_nll / len(val_loader))\n",
    "    for i, c in enumerate(model.children()):\n",
    "        if hasattr(c, 'kl_reg'):\n",
    "            effective, total = c.count_parameters()\n",
    "            logger.add_scalar(\n",
    "                epoch, \n",
    "                'sp_%s' % i, \n",
    "                effective / total\n",
    "            )\n",
    "    \n",
    "    logger.iter_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "baseline_neurons = 10000\n",
    "\n",
    "def get_score(logloss):\n",
    "    k = -1. / 0.9\n",
    "    b = 1.2 / 0.9\n",
    "    score = b + k * logloss\n",
    "    score = max(score, 0)\n",
    "    score = min(score, 1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. Estimate average log-likelihood on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "test_nll = 0\n",
    "for batch_idx, (data, target) in enumerate(val_loader):\n",
    "    data = data.to(device)\n",
    "\n",
    "    target = target.to(device)\n",
    "    output = model(data)\n",
    "\n",
    "    test_nll += nllloss(output, target).item()\n",
    "test_nll = test_nll / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2612428164431282"
      ]
     },
     "execution_count": 26,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2. Count __effective__ number of parameters in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from sparse_vd import LinearSVDO\n",
    "effecive_number_parameters = 0\n",
    "total_number_parameters = 0\n",
    "for module in model.children():\n",
    "    if isinstance(module, LinearSVDO):\n",
    "        effecive_number_parameters += module.count_parameters()[0]\n",
    "        total_number_parameters += module.count_parameters()[1]\n",
    "    else:\n",
    "        for param in module.parameters():\n",
    "            effecive_number_parameters += param.numel()\n",
    "            total_number_parameters += param.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12491, 15706)"
      ]
     },
     "execution_count": 28,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effecive_number_parameters, total_number_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### Final score is a combination of the compression score and quality of the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "final_score = get_score(test_nll) * np.log(1 + baseline_neurons / effecive_number_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Check submission files\n",
    "\n",
    "## Important notes!\n",
    "\n",
    " 1. Weights should be named as `model_weights.pt`\n",
    " 2. Edit model in `sparse_model.py`-file\n",
    " 3. `sparse_model.py` should use `LinearSVDO`-layer from `sparse_vd.py`-file\n",
    " 4. __Do not change__ `LinearSVDO`-layer definition in `sparse_vd.py`-file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's run a script to check that everything is correct and estimate score on a __train__ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on train dataset is: 0.0\r\n"
     ]
    }
   ],
   "source": [
    "!python3 test_submission.py /home/user/share/pid_sparse/training.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prepare submission\n",
    "\n",
    "Select your best classifier and prepare submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: model_weights.pt (deflated 16%)\r\n",
      "updating: sparse_model.py (deflated 60%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip submission.zip model_weights.pt sparse_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission.zip' target='_blank'>submission.zip</a><br>"
      ],
      "text/plain": [
       "/home/user/mlhep2020/Section_4/mlhep2020_pid_sparse/submission.zip"
      ]
     },
     "execution_count": 37,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(\"submission.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Ideas how to improve solution\n",
    "\n",
    "1. Optimize `kl_weight` and `threshold`\n",
    "2. Individual `threshold`'s for each layer\n",
    "3. Add learning rate scheduler\n",
    "4. Start from kl_weight = 1e-5 and gradually increase\n",
    "5. ????\n",
    "6. Your ideas :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}