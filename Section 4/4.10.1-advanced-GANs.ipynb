{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Plan\n",
    "## This notebook\n",
    "1. Super-quick intro into BaBar DIRC subdetector\n",
    "2. You create a WGAP-GP GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "___Congradulations on making it to level two of GAN practice!___\n",
    "\n",
    "Here is a bonus: a relaxing link to play with advanced GANs without writing code:\n",
    "* https://affinelayer.com/pixsrv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# BaBar DIRC\n",
    "![DIRC scheme](https://www.slac.stanford.edu/BFROOT/www/Detector/DIRC/Gifs/NewDirc.gif)\n",
    "\n",
    "Detection of Internally Reflected Cherenkov light - a particle identification detector in other words. Unlike the calorimeter GANs, we will only generate high-level observables (particle delta log-likelihoods (DLL)) that are obtained after the reconstruction.\n",
    "\n",
    "We want the generation to be conditional on full kinematics of event: energy, pseudorapidity and the distance between the particle track and DIRC bar side of signal particle. For the data-driven GAN this is just 11-D tabular data.\n",
    "\n",
    "The data were generated with [FastDIRC](https://github.com/jmhardin/FastDIRC) modified to simulate two particle-events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 1 (difficulty: a couple of years ago this would have been a [paper](https://www.sciencedirect.com/science/article/pii/S0168900219300701) in a good journal, now should be doable in 10-40 minutes*)\n",
    "\\* after Denis Derkach formulated the problem and I did all the dirty work of getting training data\n",
    "\n",
    "Create a conditional Jensen-Shannon GAN to generate Y given X\n",
    "\n",
    "### Task 2 (difficulty: ~5 lines of code after completing task 1)\n",
    "\n",
    "Create a conditional classical Wasserstein GAN wth gradient penalty to generate Y given X\n",
    "\n",
    "__Note__: Task 2 is easier to code and train than task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "URL_RE = r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "url_scrabber = re.compile(r'\\s*<input type=\"hidden\" name=\"downloadURL\" '\n",
    "                          'value=\"(?P<download_url>' + URL_RE + ')\" '\n",
    "                          'id=\"downloadURL\">')\n",
    "\n",
    "def get_cernbox_direct_link(url):\n",
    "  guard_page = requests.get(url)\n",
    "  for line in guard_page.text.split('\\n'):\n",
    "      match = url_scrabber.match(line)\n",
    "      if match:\n",
    "        return match.group('download_url')\n",
    "  raise RuntimeError(\"downloadURL not found. Most likely case is a change in CERNBox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# As usual the data is availbale in CoCalc. But if it is not, here is the link\n",
    "# data_url = get_cernbox_direct_link(\"https://cernbox.cern.ch/index.php/s/hWCh4umYQ0KShjW\")\n",
    "DATA_FILE_NAME = '/home/user/share/data/4.10.1-advanced-GANs/kaons.hdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#! wget \"$data_url\" -O \"$DATA_FILE_NAME\" -nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp, kstest\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dll_electron</th>\n",
       "      <th>dll_kaon</th>\n",
       "      <th>dll_muon</th>\n",
       "      <th>dll_proton</th>\n",
       "      <th>dll_bt</th>\n",
       "      <th>particle_one_energy</th>\n",
       "      <th>particle_two_energy</th>\n",
       "      <th>particle_one_eta</th>\n",
       "      <th>particle_two_eta</th>\n",
       "      <th>particle_one_x</th>\n",
       "      <th>particle_two_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48609366</th>\n",
       "      <td>-0.212708</td>\n",
       "      <td>2.314453</td>\n",
       "      <td>0.404724</td>\n",
       "      <td>-8.901489</td>\n",
       "      <td>-395.625427</td>\n",
       "      <td>5.761642</td>\n",
       "      <td>7.775553</td>\n",
       "      <td>-0.101042</td>\n",
       "      <td>-1.170546</td>\n",
       "      <td>4.806355</td>\n",
       "      <td>11.518691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85800802</th>\n",
       "      <td>-0.975586</td>\n",
       "      <td>7.093811</td>\n",
       "      <td>-0.254272</td>\n",
       "      <td>-118.109131</td>\n",
       "      <td>-125.633118</td>\n",
       "      <td>2.952495</td>\n",
       "      <td>4.515579</td>\n",
       "      <td>-1.027812</td>\n",
       "      <td>1.425283</td>\n",
       "      <td>8.347982</td>\n",
       "      <td>12.483961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48063890</th>\n",
       "      <td>1.210968</td>\n",
       "      <td>1.983414</td>\n",
       "      <td>-0.938339</td>\n",
       "      <td>-3.278305</td>\n",
       "      <td>-201.828049</td>\n",
       "      <td>5.667168</td>\n",
       "      <td>6.883764</td>\n",
       "      <td>0.243560</td>\n",
       "      <td>0.688672</td>\n",
       "      <td>9.765896</td>\n",
       "      <td>1.966456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6662551</th>\n",
       "      <td>-0.033142</td>\n",
       "      <td>1.237122</td>\n",
       "      <td>0.060791</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>-196.228241</td>\n",
       "      <td>6.988772</td>\n",
       "      <td>4.271856</td>\n",
       "      <td>-1.019691</td>\n",
       "      <td>-0.693035</td>\n",
       "      <td>14.185906</td>\n",
       "      <td>15.605581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89492993</th>\n",
       "      <td>0.239120</td>\n",
       "      <td>3.052887</td>\n",
       "      <td>-0.522217</td>\n",
       "      <td>-22.034760</td>\n",
       "      <td>-268.287598</td>\n",
       "      <td>5.403506</td>\n",
       "      <td>8.019310</td>\n",
       "      <td>0.975898</td>\n",
       "      <td>1.015718</td>\n",
       "      <td>6.350332</td>\n",
       "      <td>4.286400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dll_electron  dll_kaon  dll_muon  dll_proton      dll_bt  \\\n",
       "48609366     -0.212708  2.314453  0.404724   -8.901489 -395.625427   \n",
       "85800802     -0.975586  7.093811 -0.254272 -118.109131 -125.633118   \n",
       "48063890      1.210968  1.983414 -0.938339   -3.278305 -201.828049   \n",
       "6662551      -0.033142  1.237122  0.060791    0.109146 -196.228241   \n",
       "89492993      0.239120  3.052887 -0.522217  -22.034760 -268.287598   \n",
       "\n",
       "          particle_one_energy  particle_two_energy  particle_one_eta  \\\n",
       "48609366             5.761642             7.775553         -0.101042   \n",
       "85800802             2.952495             4.515579         -1.027812   \n",
       "48063890             5.667168             6.883764          0.243560   \n",
       "6662551              6.988772             4.271856         -1.019691   \n",
       "89492993             5.403506             8.019310          0.975898   \n",
       "\n",
       "          particle_two_eta  particle_one_x  particle_two_x  \n",
       "48609366         -1.170546        4.806355       11.518691  \n",
       "85800802          1.425283        8.347982       12.483961  \n",
       "48063890          0.688672        9.765896        1.966456  \n",
       "6662551          -0.693035       14.185906       15.605581  \n",
       "89492993          1.015718        6.350332        4.286400  "
      ]
     },
     "execution_count": 7,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_hdf(DATA_FILE_NAME)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "Y_COLUMNS = [\"particle_one_energy\",\n",
    "             \"particle_two_energy\",\n",
    "             \"particle_one_eta\",\n",
    "             \"particle_two_eta\",\n",
    "             \"particle_one_x\",\n",
    "             \"particle_two_x\"]\n",
    "X_COLUMNS = [\"dll_electron\",\n",
    "             \"dll_kaon\",\n",
    "             \"dll_muon\",\n",
    "             \"dll_proton\",\n",
    "             \"dll_bt\"]\n",
    "assert X_COLUMNS + Y_COLUMNS == list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 9,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If feel physically inclined, feel free to make a hundred of plots.\n",
    "# However, for purposes of this exercise, abstract tabular X, Y will suffice.\n",
    "# In order to achive this wonderful state, the data needs to be normalized.\n",
    "plt.hist(data.values[:, 0], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "checksum": "2d3ff379d5ad5af0632c9b8af7af33ae",
     "grade": false,
     "grade_id": "6b1bab",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# Please use the sklearn.preprocessing.QuantileTransformer to transform each feature\n",
    "# into a Gaussian\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "# Will take a couple of minutes\n",
    "# Please use the data_transformed variable to store the transfored dataset\n",
    "qt = QuantileTransformer(n_quantiles=10000, output_distribution='normal', random_state=42)\n",
    "data_transformed = qt.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After the transformation, features should look like this:\n",
    "![feature after normalization](https://github.com/yandexdataschool/mlhep2019/raw/master/notebooks/day-6/gauss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 11,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(data_transformed[:, 0], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "e6d15d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
   ],
   "source": [
    "assert data_transformed.shape == data.shape\n",
    "for feature in range(data_transformed.shape[1]):\n",
    "    assert kstest(data_transformed[:, feature], 'norm').statistic < 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "train, test = train_test_split(data_transformed, test_size=0.1, random_state=124124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "LATENT_DIM = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Please create a fully-connected generator. Remember, we need a conditional GAN, so the generator input should have dimensions for Y and noise; output - for X.\n",
    "\n",
    "You can start with a small one, make sure the code works, then add more layers. Having 3 hidden layer with 64 neurons in each should suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "checksum": "6308b34fb639c80a997d96084b7761ed",
     "grade": false,
     "grade_id": "ccfe09",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
   ],
   "source": [
    "# Note that WGAN does not work well with ELU (as per my experience and the original paper)\n",
    "gen = nn.Sequential(nn.Linear(data.shape[1], 64), nn.LeakyReLU(),\n",
    "                     nn.Linear(64, 64), nn.LeakyReLU(),\n",
    "                     nn.Linear(64, 64), nn.LeakyReLU(),\n",
    "                     nn.Linear(64, 1)).cuda()\n",
    "gen_opt = torch.optim.RMSprop(gen.parameters(), lr=1e-2)\n",
    "gen_scheduler = torch.optim.lr_scheduler.MultiStepLR(gen_opt, milestones=[10000, 30000], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "e8e847",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-befb861604ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLATENT_DIM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_COLUMNS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_COLUMNS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert gen[0].in_features == LATENT_DIM + len(Y_COLUMNS)\n",
    "assert gen[-1].out_features == len(X_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Please create a fully-connected discriminator. You can start with a small one, make sure the code works, then add more layers. Having 3 hidden layer with 64 neurons in each should suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "checksum": "ed62ee72433db6077b9c9f127872a1fb",
     "grade": false,
     "grade_id": "6adfae",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
   ],
   "source": [
    "disc = nn.Sequential(nn.Linear(data.shape[1], 64), nn.LeakyReLU(),\n",
    "                     nn.Linear(64, 64), nn.LeakyReLU(),\n",
    "                     nn.Linear(64, 64), nn.LeakyReLU(),\n",
    "                     nn.Linear(64, 1)).cuda()\n",
    "\n",
    "disc_opt = torch.optim.RMSprop(disc.parameters(), lr=1e-2)\n",
    "disc_scheduler = torch.optim.lr_scheduler.MultiStepLR(disc_opt, milestones=[10000, 30000], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "assert disc[0].in_features == data.shape[1]\n",
    "assert disc[-1].out_features == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "TRAIN_BATCH_SIZE = 1024\n",
    "def sample_real_data(batch_size):\n",
    "  \"\"\"\n",
    "  Inifintly repeats and shuffles the train dataset, outputs the\n",
    "  result in delicious batches.\n",
    "  \"\"\"\n",
    "  while True:\n",
    "    dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size,\n",
    "                                             shuffle=True, drop_last=True)\n",
    "    for batch in dataloader:\n",
    "        yield batch\n",
    "infinite_data = sample_real_data(TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Write a function that would sample the generator for given Y. The function should return a GPU-based tensor.\n",
    "\n",
    "`concatenate(generator(concatenate(noise, y)), y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "checksum": "f4d572e329fd609794e205f4a7dba89a",
     "grade": false,
     "grade_id": "d42f29",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2ecdd467a96c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# sample_gen_data(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sample_gen_data(y)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_gen_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fc2a2ce0a11a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_gen_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_COLUMNS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_gen_data' is not defined"
     ]
    }
   ],
   "source": [
    "test_sample = sample_gen_data(torch.from_numpy(train[:3, len(X_COLUMNS):]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "2d3697",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-dbd6dbb14b03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtest_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_sample' is not defined"
     ]
    }
   ],
   "source": [
    "assert test_sample.shape == (3, data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# https://github.com/caogang/wgan-gp/blob/master/gan_mnist.py\n",
    "def calc_gradient_penalty_classic(critic:torch.nn.Module,\n",
    "                                  real_data:torch.Tensor,\n",
    "                                  fake_data:torch.Tensor):\n",
    "    \"\"\"\n",
    "    Computes Gradient Penalty in random interpolates, in its classic form:\n",
    "    (|âˆ‡(D(x)|^2 - 1)^2, x is interpolated between a real and a generated sample\n",
    "    Args:\n",
    "    critic: a torch model whose gradient needs to be penalised\n",
    "    real_data[batch_size, n_features]: a sample of real data\n",
    "    fakse_data[batch_size, n_features]: a sample of fake data\n",
    "    Returns:\n",
    "    torch.Tensor, scalar, gradient penalty evalute\n",
    "    \"\"\"\n",
    "    assert real_data.shape == fake_data.shape\n",
    "    alpha = torch.rand(real_data.shape[0], 1)\n",
    "    alpha = alpha.expand(real_data.size()).cuda()\n",
    "\n",
    "    interpolates = (alpha * real_data + ((1 - alpha) * fake_data)).cuda()\n",
    "    interpolates = torch.autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    disc_interpolates = critic(interpolates)\n",
    "\n",
    "    gradients = torch.autograd.grad(\n",
    "      outputs=disc_interpolates, inputs=interpolates,\n",
    "      grad_outputs=torch.ones(disc_interpolates.size(), device=\"cuda\"),\n",
    "      create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "LAMBDA = 1.\n",
    "def train_disc(gan_type=\"WGAN-GP\"):\n",
    "    \"\"\"\n",
    "    Trains the discriminator for one step. Please note\n",
    "    this is not a pure function, it captutes the majority of variables\n",
    "    from the context.\n",
    "    \"\"\"\n",
    "    real_data = next(infinite_data).to(\"cuda\")\n",
    "    y_gen = next(infinite_data)[:, len(X_COLUMNS):].to(\"cuda\")\n",
    "    gen_data = sample_gen_data(y_gen)\n",
    "\n",
    "    if gan_type == \"JS\":\n",
    "        logp_real_is_real = F.logsigmoid(disc(real_data))\n",
    "        logp_gen_is_fake = F.logsigmoid(-disc(gen_data))\n",
    "        disc_loss = -logp_real_is_real.mean() - logp_gen_is_fake.mean()\n",
    "    elif gan_type == \"WGAN-GP\":\n",
    "        disc_loss = disc(real_data).mean() - disc(gen_data).mean() + \\\n",
    "                  calc_gradient_penalty_classic(disc, real_data, gen_data)*LAMBDA\n",
    "    else:\n",
    "        raise ValueError(\"Unknown GAN type. Valid ones are: JS, WGAN-GP\")\n",
    "\n",
    "    disc_opt.zero_grad()\n",
    "    disc_loss.backward()\n",
    "    disc_opt.step()\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "checksum": "6a9affd84cc8577798a4a2d4dda925be",
     "grade": false,
     "grade_id": "fc320f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
   ],
   "source": [
    "def train_gen(gan_type=\"WGAN-GP\"):\n",
    "    \"\"\"Trains generator for one step\"\"\"\n",
    "    real_data_y = next(infinite_data)[:, len(X_COLUMNS):].to(\"cuda\")\n",
    "    gen_data = sample_gen_data(real_data_y)\n",
    "\n",
    "    if gan_type == \"JS\":\n",
    "        # gen_loss = <your code here>\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    elif gan_type == \"WGAN-GP\":\n",
    "        # gen_loss = <your code here>\n",
    "        ### BEIGN SOLUTION\n",
    "        gen_loss = disc(gen_data).mean()\n",
    "\n",
    "    gen_opt.zero_grad()\n",
    "    gen_loss.backward()\n",
    "    gen_opt.step()\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "TENSORBOARD_LOGDIR = \"./logs\"\n",
    "MODEL_NAME = \"DIRCv1\"\n",
    "summary_writer = SummaryWriter(log_dir=os.path.join(TENSORBOARD_LOGDIR, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_gen_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c79aba974147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDISCRIMINATOR_ITERATIONS_PER_GENEREATOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdisc_loss_this_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_disc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mgen_loss_this_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-760f003407cf>\u001b[0m in \u001b[0;36mtrain_disc\u001b[0;34m(gan_type)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mreal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfinite_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfinite_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_COLUMNS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mgen_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_gen_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgan_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"JS\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_gen_data' is not defined"
     ]
    }
   ],
   "source": [
    "DISCRIMINATOR_ITERATIONS_PER_GENEREATOR = 5\n",
    "VALIDATION_INTERVAL = 256\n",
    "HIST_BINS=100\n",
    "DATA_HIST_RANGE=[-5, 5]\n",
    "\n",
    "data_linspace_np = np.linspace(0, 10, num=256, dtype=np.float32)\n",
    "data_linspace_torch = torch.from_numpy(data_linspace_np)[:, None].cuda()\n",
    "validation_data = torch.from_numpy(test).cuda()\n",
    "validation_data_np = test\n",
    "validation_y = validation_data[:, len(X_COLUMNS):]\n",
    "\n",
    "for i in range(10000):\n",
    "    for _ in range(DISCRIMINATOR_ITERATIONS_PER_GENEREATOR):\n",
    "        disc_loss_this_iter = train_disc()\n",
    "\n",
    "    gen_loss_this_iter = train_gen()\n",
    "    gen_scheduler.step()\n",
    "    disc_scheduler.step()\n",
    "    summary_writer.add_scalar(\"discriminator loss\", disc_loss_this_iter,\n",
    "                              global_step=i)\n",
    "    summary_writer.add_scalar(\"generator loss\", gen_loss_this_iter,\n",
    "                              global_step=i)\n",
    "    if i % VALIDATION_INTERVAL == 0:\n",
    "        clear_output(True)\n",
    "        validation_generated = sample_gen_data(validation_y)\n",
    "        validation_generated_np = validation_generated.data.cpu().numpy()\n",
    "\n",
    "        fig, axes_list = plt.subplots(ncols=5, figsize=[6*len(Y_COLUMNS), 6])\n",
    "        for index, ax in enumerate(axes_list):\n",
    "          ax.hist(validation_generated_np[:, index], range=DATA_HIST_RANGE,\n",
    "                  alpha=0.5, density=True, label='Generated', bins=HIST_BINS)\n",
    "          ax.hist(validation_data_np[:, index], range=DATA_HIST_RANGE,\n",
    "                  alpha=0.5, density=True, label='Real', bins=HIST_BINS)\n",
    "          ax.set_xlabel(data.columns[index])\n",
    "          ks_result = ks_2samp(validation_generated_np[:, index],\n",
    "                                    validation_data_np[:, index])\n",
    "          ax.set_title(\"KS stat = {:.4f}; p-value = {:.4E}\".format(*tuple(ks_result)))\n",
    "        fig.suptitle(\"Iteration {}\".format(i))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After a little bit of training, the plots should look like this: ![semitrained GAN](https://github.com/yandexdataschool/mlhep2019/raw/master/notebooks/day-6/semi-trained.png)\n",
    "\n",
    "If you want to push precision to the limit, you want to increase batch size and reduce learning rate over time. You'll also need to monitor the validation losses to avoid overfitting.\n",
    "\n",
    "P. S.\n",
    "As you know from the [lectures](https://en.pelican.study/classroom/213/dialogs/2614/run/), these plots do not comprehensively describe the quality of the GAN. Feel free to add better quality measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}