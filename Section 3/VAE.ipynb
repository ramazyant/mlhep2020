{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "x_Dd0j4pcw9-"
   },
   "outputs": [
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "x_Dd0j4pcw9-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected cuda:2\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "def get_free_gpu():\n",
    "    from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo, nvmlDeviceGetCount\n",
    "    nvmlInit()\n",
    "\n",
    "    return np.argmax([\n",
    "        nvmlDeviceGetMemoryInfo(nvmlDeviceGetHandleByIndex(i)).free\n",
    "        for i in range(nvmlDeviceGetCount())\n",
    "    ])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cuda_id = get_free_gpu()\n",
    "    device = 'cuda:%d' % (get_free_gpu(), )\n",
    "    print('Selected %s' % (device, ))\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('WARNING: using cpu!')\n",
    "\n",
    "### please, don't remove the following line\n",
    "x = torch.tensor([1], dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "x_Dd0j4pcw9-"
   },
   "outputs": [
   ],
   "source": [
    "# Training dataset\n",
    "binarizing_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    lambda x: x>0.5,\n",
    "    lambda x: x.float()])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    MNIST(root='../../data', train=True, download=True,\n",
    "          transform=binarizing_transform),\n",
    "    batch_size=100, shuffle=True, pin_memory=True)\n",
    "# Test dataset\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    MNIST(root='../../data', train=False,\n",
    "          transform=binarizing_transform),\n",
    "    batch_size=100, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "_c1mRNbLct6G"
   },
   "source": [
    "# Practical Session. Variational Autoencoders\n",
    "\n",
    "In this session you will implement a vanilla VAE on MNIST dataset. The implementation will be based on the [*torch.distributions*](https://pytorch.org/docs/stable/distributions.html) module.\n",
    "\n",
    "To complete the task, you will need construct the loss function using the distributions module and then train the model.\n",
    "\n",
    "### Goal:\n",
    "The goal is to train and study a variational auto-encoder to approximate the dataset distribution, namely a distribution of low-resolution binary hand-written digits. To achieve the goal you should only implement the loss function for the variational auto-encoder.\n",
    "\n",
    "### Data:\n",
    "\n",
    "The dataset consists of 70000 binary images with hand-written digits of size $ 28 \\times 28 $ .\n",
    "\n",
    "### Criteria:\n",
    "\n",
    "The main training criterion for variational-autoencoders is the average log-likelihood on the test set. For simplicity, we will use the evidence lower bound (ELBO, a lower bound on log-likelihood) instead of the likelihood. Recall that the evidence lower bound is the training objective of VAE. For the correct implementation of the loss function the average loss (negative ELBO) on a test set should be close to 95.\n",
    "\n",
    "After traning the model should be able to reconstruct input digits (run *plot_reconstructions*, are outputs reasonable?) and interpolate between digits in the latent space (run *plot_interpolations*, are outputs reasonable?). \n",
    "\n",
    "In the last cell we project latent codes of test data on a 2d plane. The points color represents the digits from the original image. The projection algorithm preserves local distances (if points are close on a picture, they were close in the original space). The points on the plane form clusters for different digits. Similar digits should have close clusters.\n",
    "\n",
    "# Motivation: AEs  vs. VAEs\n",
    "\n",
    "Below are pair of MNIST images and reconstructions built with an auto-encoder. Notably, autoencoders can provide good reconstruction quality.\n",
    "\n",
    "![Autoencoder reconstructions](https://github.com/bayesgroup/deepbayes-2018/blob/master/day2_vae/ae_reconstructions.png?raw=true)\n",
    "\n",
    "Still, the model has no control over the learned latent representations. For example, an interpolation of latent representations of two digits is typically not a latent representation for a digit:\n",
    "\n",
    "![Autoencoder interpolations](https://github.com/bayesgroup/deepbayes-2018/blob/master/day2_vae/ae_interpolations.png?raw=true)\n",
    "\n",
    "On the other hand, a standard VAE model forces latent representation to fit a multivariate Gaussian distribution. As a result, an interpolation of two latent representations is likely to be a latent representation of a digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "YCGwVlZWdUA-"
   },
   "source": [
    "# Distributions for VAE\n",
    "\n",
    "For the assignment, we will need two types of distributions to define the probabilistic model.\n",
    "1. For the latent variable $z$ we need a vector of independent [normally distributed](https://pytorch.org/docs/stable/distributions.html#normal) scalars.\n",
    "2. For observations $x$, we will need a vector of independent [Bernoulli](https://pytorch.org/docs/stable/distributions.html#bernoulli) random variables.\n",
    "3. By default, the classes model a tensor of independent random **variables**. To represent a matrix of independent random variables as a batch of random **vectors** you may also use the [Independent](https://pytorch.org/docs/stable/distributions.html#independent) class.\n",
    "\n",
    "### Bernoulli random vector\n",
    "\n",
    "In the task, the class to models $p(x | z)$ parametrized by the output of the decoder. To define the loss function you will need to compute $\\log p(x | z)$ for input images using *log_prob()* method.\n",
    "\n",
    "*Tip:* While the class can be initialized both with probabilities and logits, the best practice is to initialize the class with logits. Otherwise, computing logarithm of probability can be highly unstable. \n",
    "\n",
    "\n",
    "### Normal Distribution\n",
    "\n",
    "In this task, you will use the class to define the approximate posterior distribution $q(x | z)$ and the latent variable distribution $p(z)$. Again, you will use *log_prob()* method to compute the loss function.\n",
    "\n",
    "**Importantly,** VAE generates a sample from $q(x | z)$ to pass it to the decoder. To implement the reparametrization trick the class defines a specific sampling method *rsample()*, that computes $z = \\mu(x) + \\varepsilon \\odot \\sigma(x)$ for standard Gaussian noise $\\varepsilon$. Notice that the implementation of *rsample()* method differs from the implementation of *sample()* method.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "9r_hPaHx0Jz1"
   },
   "outputs": [
   ],
   "source": [
    "from torch.distributions import Normal, Bernoulli, Independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "5wtFSf25dXjx"
   },
   "source": [
    "# Quick references:\n",
    "\n",
    "## Vanilla VAE Specification\n",
    "\n",
    "Probabilistic model: \n",
    "\\begin{align}\n",
    "& p(x, z \\mid \\theta) =  p(z) p(x \\mid z, \\theta) \\\\\n",
    "& p(z) = \\mathcal N(z \\mid 0, I) \\\\\n",
    "& p(x \\mid z, \\theta) = \\prod_{i = 1}^D f_i(z, \\theta)^{x_i} (1 - f_i(z, \\theta))^{1 - x_i}.\n",
    "\\end{align}\n",
    "Inference model:\n",
    "\\begin{equation}\n",
    "q(z \\mid x, \\phi) = \\mathcal N(z \\mid \\mu(x, \\phi), \\operatorname{diag}(\\sigma^2(x, \\phi))).\n",
    "\\end{equation}\n",
    "Objective for a single sample $x$:\n",
    "$$ \\mathcal L(x, \\theta, \\phi) = \\mathbb E_{q(z \\mid x, \\phi)} \\left[ \\log p(x \\mid z, \\phi) + \\log p(z) - \\log q(z \\mid x, \\theta) \\right] $$\n",
    "Objective estimate for a single sample $x$:\n",
    "\\begin{align*}\n",
    "\\log p(x \\mid z_0, \\phi) + \\log p(z_0) - \\log q(z_0 \\mid x, \\theta) \\\\\n",
    "z_0 = \\mu(x, \\phi) + \\sigma^2(x, \\phi)^T \\varepsilon_0 \\\\\n",
    "\\varepsilon_0 \\sim \\mathcal N(0, I)\n",
    "\\end{align*}\n",
    "\n",
    "Tip: to train the model we average the lower bound values over the minibatch of $x$ and then maximize the estimate with gradient ascent.\n",
    "\n",
    "## Encoder and decoder parametrization\n",
    "\n",
    "VAE uses two neural netowrk to parametrize two distributions introduced above:\n",
    "\n",
    "- Encoder (*enc*) takes $x$ as input and return $2 \\times d$-dimensional vector to parametrize mean and standard deviation of $q(z \\mid x, \\theta)$\n",
    "- Decoder (*dec*) takes a latent representation $z$ and returns the logits of distribution $p(x \\mid z, \\phi)$.\n",
    "\n",
    "The computational graph has a simple structure of autoencoder. The only difference is that now it uses a stochastic variable $\\varepsilon$:\n",
    "\n",
    "![vae](https://github.com/bayesgroup/deepbayes-2018/blob/master/day2_vae/vae.png?raw=true)\n",
    "\n",
    "Below we initialize a couple of simple fully-connected networks to model the two distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "pakTj8-gc6SZ"
   },
   "outputs": [
   ],
   "source": [
    "d, nh, D = 32, 100, 28 * 28\n",
    "\n",
    "enc = nn.Sequential(\n",
    "    nn.Linear(D, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, 2 * d)) # note that the final layer outputs real values\n",
    "\n",
    "dec = nn.Sequential(\n",
    "    nn.Linear(d, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, D)).to(device) # <-----------------------------------------------\n",
    "\n",
    "enc = enc.to(device)\n",
    "dec = dec.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "-xqmyAtbfmhG"
   },
   "source": [
    "## Task: VAE Loss function\n",
    "\n",
    "Implement the loss function for the variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "ymwPo9E3erVB",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a36b428c4e75c1d9eea07f7345a6585",
     "grade": false,
     "grade_id": "03bf85",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
   ],
   "source": [
    "def loss_vae(x, encoder, decoder):\n",
    "    \"\"\" \n",
    "    TODO\n",
    "    \n",
    "    input:\n",
    "    x is a tensor of shape (batch_size x 784)\n",
    "    encoder is a nn.Module that follows the above specification\n",
    "    decoder is a nn.Mudule that follows the above specification\n",
    "    \n",
    "    output:\n",
    "    1. the avergave value of negative ELBO across the minibatch x\n",
    "    2. and the output of the decoder\n",
    "    \"\"\"    \n",
    "    loss = \n",
    "    decoder_output = \n",
    "    return loss, decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "dIMpMloYfyJT"
   },
   "source": [
    "After implementing the loss run the followings cells to train VAE and visualise several examples.\n",
    "\n",
    "## Training\n",
    "The cell below implements a simple training function that can be used for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "qLI_soZRfzBM"
   },
   "outputs": [
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def train_model(loss, model, batch_size=100, num_epochs=3, learning_rate=1e-3):\n",
    "    gd = torch.optim.Adam(\n",
    "        chain(*[x.parameters() for x in model\n",
    "                if (isinstance(x, nn.Module) or isinstance(x, nn.Parameter))]),\n",
    "        lr=learning_rate)\n",
    "    train_losses = []\n",
    "    test_results = []\n",
    "    for _ in range(num_epochs):\n",
    "        for i, (batch, _) in enumerate(train_loader):\n",
    "            total = len(train_loader)\n",
    "            gd.zero_grad()\n",
    "            batch = batch.view(-1, D).to(device)\n",
    "            loss_value, _ = loss(batch, *model)\n",
    "            loss_value.backward()\n",
    "            train_losses.append(loss_value.item())\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print('\\rTrain loss:', train_losses[-1],\n",
    "                      'Batch', i + 1, 'of', total, ' ' * 10, end='', flush=True)\n",
    "            gd.step()\n",
    "        test_loss = 0.\n",
    "        for i, (batch, _) in enumerate(test_loader):\n",
    "            \n",
    "            batch = batch.view(-1, D).to(device)\n",
    "            batch_loss, _ = loss(batch, *model)\n",
    "            test_loss += (batch_loss - test_loss) / (i + 1)\n",
    "        print('\\nTest loss after an epoch: {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "lPjL_TOpf17s"
   },
   "outputs": [
   ],
   "source": [
    "# my implementation has test loss ~96\n",
    "train_model(loss_vae, model=[enc, dec], num_epochs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "McWlphgdf5ip"
   },
   "source": [
    "## Visualisations\n",
    "\n",
    "- How do reconstruction compare to reconstructions of autoencoder?\n",
    "- Interpolations?\n",
    "- Is the latent space regularly covered? \n",
    "- Is there any dependence between T-SNE encoding and the digit label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "pgFFrXPxkNAh"
   },
   "outputs": [
   ],
   "source": [
    "def sample_vae(dec, n_samples=50):\n",
    "    # this function returns the mean of p(x | z), not a sample from p(x | z)\n",
    "    # so, being accurate, the output is not a sample from vae\n",
    "    # but the mean value is more informative for visualization\n",
    "    with torch.no_grad():\n",
    "        samples = torch.sigmoid(dec(torch.randn(n_samples, d).to(device)))\n",
    "        samples = samples.view(n_samples, 28, 28).cpu().numpy()\n",
    "    return samples\n",
    "    \n",
    "def plot_samples(samples, h=5, w=10):\n",
    "    fig, axes = plt.subplots(nrows=h,\n",
    "                             ncols=w,\n",
    "                             figsize=(int(1.4 * w), int(1.4 * h)),\n",
    "                             subplot_kw={'xticks': [], 'yticks': []})\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        ax.imshow(samples[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "jX7z79vpAUp1",
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "plot_samples(sample_vae(dec=dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "TVfp4hfbf66d"
   },
   "outputs": [
   ],
   "source": [
    "def plot_reconstructions(loss, model):\n",
    "    with torch.no_grad():\n",
    "        batch = (test_loader.dataset.data[:25].float() / 255.)\n",
    "        batch = (batch > 0.5).float()\n",
    "        batch = batch.view(-1, D).to(device)\n",
    "        _, rec = loss(batch, *model)\n",
    "        rec = torch.sigmoid(rec)\n",
    "        rec = rec.view(-1, 28, 28).cpu().numpy()\n",
    "        batch = batch.view(-1, 28, 28).cpu().numpy()\n",
    "    \n",
    "        fig, axes = plt.subplots(nrows=5, ncols=10, figsize=(14, 7),\n",
    "                                 subplot_kw={'xticks': [], 'yticks': []})\n",
    "        for i in range(25):\n",
    "            axes[i % 5, 2 * (i // 5)].imshow(batch[i], cmap='gray')\n",
    "            axes[i % 5, 2 * (i // 5) + 1].imshow(rec[i], cmap='gray')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Fn1cLF_BgAN2"
   },
   "outputs": [
   ],
   "source": [
    "plot_reconstructions(loss_vae, [enc, dec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "-Ye1dch0gCmp"
   },
   "outputs": [
   ],
   "source": [
    "def plot_interpolations(encoder, decoder):\n",
    "    with torch.no_grad():\n",
    "        batch = (test_loader.dataset.data[:10].float() / 255.)\n",
    "        batch = (batch > 0.5).float()\n",
    "        batch = batch.view(-1, D).to(device)\n",
    "        batch = encoder(batch)\n",
    "        z_0 = batch[:5, :d].view(5, 1, d)\n",
    "        z_1 = batch[5:, :d].view(5, 1, d)\n",
    "        \n",
    "        alpha = torch.linspace(0., 1., 10).to(device)\n",
    "        alpha = alpha.view(1, 10, 1)\n",
    "        \n",
    "        interpolations_z = (z_0 * alpha + z_1 * (1 - alpha))\n",
    "        interpolations_z = interpolations_z.view(50, d)\n",
    "        interpolations_x = torch.sigmoid(decoder(interpolations_z))\n",
    "        interpolations_x = interpolations_x.view(5, 10, 28, 28).cpu().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=5, ncols=10, figsize=(14, 7),\n",
    "                             subplot_kw={'xticks': [], 'yticks': []})\n",
    "    for i in range(50):\n",
    "        axes[i // 10, i % 10].imshow(interpolations_x[i // 10, i % 10], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "vi5Kw-KOgFky"
   },
   "outputs": [
   ],
   "source": [
    "plot_interpolations(enc, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "tR-VF5QdgHSP"
   },
   "outputs": [
   ],
   "source": [
    "def plot_tsne(objects, labels):\n",
    "    from sklearn.manifold import TSNE\n",
    "    embeddings = TSNE(n_components=2).fit_transform(objects)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for k in range(10):\n",
    "        embeddings_for_k = embeddings[labels == k]\n",
    "        plt.scatter(embeddings_for_k[:, 0], embeddings_for_k[:, 1],\n",
    "                    label='{}'.format(k))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "6vFlGlKogJ4i"
   },
   "outputs": [
   ],
   "source": [
    "with torch.no_grad():\n",
    "    batch = (test_loader.dataset.data[:1000].float() / 255.)\n",
    "    batch = (batch > 0.5).float()\n",
    "    batch = batch.view(-1, D).to(device)\n",
    "\n",
    "    latent_variables = enc(batch)[:, :d]\n",
    "    latent_variables = latent_variables.cpu().numpy()\n",
    "    labels = test_loader.dataset.targets[:1000].numpy()\n",
    "  \n",
    "plot_tsne(latent_variables, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The notebook implements a basic variational auto-encoder. Even with a toy architecture the model manages to learn a crude approximation of the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
   ],
   "name": "deep_bayes_VAE_blank.ipynb",
   "provenance": [
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}