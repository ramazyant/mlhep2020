{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><center><img src=\"img/mlhep-logo-transparent.png\" width=\"400\"></center></td>\n",
    "    <td><h1><center>The Sixth Machine Learning in High Energy Physics Summer School (MLHEP) 2020</center></h1></td>\n",
    "  </tr>\n",
    " </table>\n",
    "\n",
    "<h1><center>Seminar</center></h1>\n",
    "<h2><center>Cross-Validation, Quality Metric Uncertainty Estimation, <br>Statistical Model Comparison</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.testing as np_testing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 1: Quality metric uncertainty estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data preparation\n",
    "\n",
    "UCI MAGIC dataset: https://archive.ics.uci.edu/ml/datasets/magic+gamma+telescope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The data are MC generated (see below) to simulate registration of high energy gamma particles in a ground-based atmospheric Cherenkov gamma telescope using the imaging technique. Cherenkov gamma telescope observes high energy gamma rays, taking advantage of the radiation emitted by charged particles produced inside the electromagnetic showers initiated by the gammas, and developing in the atmosphere. This Cherenkov radiation (of visible to UV wavelengths) leaks through the atmosphere and gets recorded in the detector, allowing reconstruction of the shower parameters. The available information consists of pulses left by the incoming Cherenkov photons on the photomultiplier tubes, arranged in a plane, the camera. Depending on the energy of the primary gamma, a total of few hundreds to some 10000 Cherenkov photons get collected, in patterns (called the shower image), allowing to discriminate statistically those caused by primary gammas (signal) from the images of hadronic showers initiated by cosmic rays in the upper atmosphere (background).\n",
    "\n",
    "Features description:\n",
    "- **Length:** continuous # major axis of ellipse [mm]\n",
    "- **Width:** continuous # minor axis of ellipse [mm]\n",
    "- **Size:** continuous # 10-log of sum of content of all pixels [in #phot]\n",
    "- **Conc:** continuous # ratio of sum of two highest pixels over fSize [ratio]\n",
    "- **Conc1:** continuous # ratio of highest pixel over fSize [ratio]\n",
    "- **Asym:** continuous # distance from highest pixel to center, projected onto major axis [mm]\n",
    "- **M3Long:** continuous # 3rd root of third moment along major axis [mm]\n",
    "- **M3Trans:** continuous # 3rd root of third moment along minor axis [mm]\n",
    "- **Alpha:** continuous # angle of major axis with vector to origin [deg]\n",
    "- **Dist:** continuous # distance from origin to center of ellipse [mm]\n",
    "- **Label:** g,h # gamma (signal), hadron (background)\n",
    "\n",
    "g = gamma (signal): 12332 \\\n",
    "h = hadron (background): 6688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Size</th>\n",
       "      <th>Conc</th>\n",
       "      <th>Conc1</th>\n",
       "      <th>Asym</th>\n",
       "      <th>M3Long</th>\n",
       "      <th>M3Trans</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Dist</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Length     Width    Size    Conc   Conc1      Asym   M3Long  M3Trans  \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110  -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238  -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580 -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633  -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525  21.8393   \n",
       "\n",
       "     Alpha      Dist Label  \n",
       "0  40.0920   81.8828     g  \n",
       "1   6.3609  205.2610     g  \n",
       "2  76.9600  256.7880     g  \n",
       "3  10.4490  116.7370     g  \n",
       "4   4.6480  356.4620     g  "
      ]
     },
     "execution_count": 2,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_names = np.array([\"Length\", \"Width\", \"Size\", \"Conc\", \"Conc1\", \"Asym\", \"M3Long\", \"M3Trans\", \"Alpha\", \"Dist\"])\n",
    "\n",
    "data = pd.read_csv(\"data/MAGIC/magic04.data\", header=None, names=list(f_names)+[\"Label\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# prepare a matrix of input features\n",
    "X = data[f_names].values\n",
    "\n",
    "# prepare a vector of true labels\n",
    "y = 1 * (data['Label'].values == \"g\")\n",
    "\n",
    "\n",
    "\n",
    "# scale data (apply to X, y for the further simplisity)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scale data: X = (X - mean) / sigma\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into train and test subsamples to fit and test classifiers\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=11, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Fit a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=11)"
      ]
     },
     "execution_count": 5,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import Logistic Regression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# define a classifier\n",
    "logreg = LogisticRegression(penalty='l2', C=1.0, max_iter=1000, class_weight=None, solver='lbfgs', random_state=11)\n",
    "\n",
    "# fit it using the train subsample\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# get predictions for the test subsample\n",
    "y_test_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# predict labels\n",
    "y_test_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proba:  [9.22801236e-01 5.92866289e-04 7.62689962e-01 5.53478948e-01\n",
      " 7.68378253e-01]\n",
      "Pred:   [1 0 1 1 1]\n",
      "True:   [0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Proba: \", y_test_proba[:5])\n",
    "print(\"Pred:  \", y_test_pred[:5])\n",
    "print(\"True:  \", y_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Compute quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def quality_metrics_report(y_true, y_pred, y_proba):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: array-like of shape (n_samples,)\n",
    "        Ground truth (correct) target values.\n",
    "    y_pred: array-like of shape (n_samples,)\n",
    "        Estimated targets as returned by a classifier.\n",
    "    y_proba : array, shape = [n_samples]\n",
    "        Target scores, can be probability estimates of the positive\n",
    "        class.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List of metric values: [accuracy, precision, recall, f1, roc_auc]\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracy  = metrics.accuracy_score(y_true, y_pred)\n",
    "    precision = metrics.precision_score(y_true, y_pred)\n",
    "    recall    = metrics.recall_score(y_true, y_pred)\n",
    "    f1        = metrics.f1_score(y_true, y_pred)\n",
    "    roc_auc   = metrics.roc_auc_score(y_true, y_proba)\n",
    "    \n",
    "    return [accuracy, precision, recall, f1, roc_auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sample:\n",
      "Accuracy:   0.7915878023133543\n",
      "Precision:  0.8037166085946573\n",
      "Recall:     0.8978267920856309\n",
      "F1-score:   0.8481691435575303\n",
      "ROC AUC:    0.8367635664478921\n"
     ]
    }
   ],
   "source": [
    "# compute roc auc score on the test\n",
    "[accuracy, precision, recall, f1, roc_auc] = quality_metrics_report(y_test, y_test_pred, y_test_proba)\n",
    "\n",
    "print(\"Test sample:\")\n",
    "print(\"Accuracy:  \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall:    \", recall)\n",
    "print(\"F1-score:  \", f1)\n",
    "print(\"ROC AUC:   \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Quality metric uncertainty estimation with Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<center><img src=\"img/bootstrap.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Uncertainty estimation with bootstrap:\n",
    "\n",
    "1. Given a model fitted on a train sample\n",
    "2. ùëÅ ‚Äì number of objects in a test sample\n",
    "3. For ùëñ=1, ‚Ä¶, ùêµ do: \\\n",
    "    3.1 Sample with replacement a subsample with ùëÅ objects from the test sample \\\n",
    "    3.2 Calculate quality metrics on this subsample\n",
    "4. Estimate statistics of the metrics: mean, variance, confidence intervals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 1\n",
    "Estimate the quality metrics uncertainties for the classifier considered above. For this, complete the function below.\n",
    "\n",
    "**Hint:** to sample indeces with replacements use `np.random.choice()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "377ba294f88a8aaa00aca17b4b51cc8c",
     "grade": false,
     "grade_id": "85c90a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
   ],
   "source": [
    "def botstrap_uncertainties(model, X_test, y_test, iters=100):\n",
    "    \n",
    "    metrics = []\n",
    "    \n",
    "    for i in range(iters):\n",
    "        \n",
    "        # you need to sample a subsample indeces using np.random.choice():\n",
    "        # inds_boot = ...\n",
    "        inds_boot = np.random.choice(np.arange(len(X_test)), size=len(X_test))\n",
    "        \n",
    "        X_test_boot = X_test[inds_boot]\n",
    "        y_test_boot = y_test[inds_boot]\n",
    "        \n",
    "        # make prediction\n",
    "        y_test_proba_boot = model.predict_proba(X_test_boot)[:, 1]\n",
    "        y_test_pred_boot  = model.predict(X_test_boot)\n",
    "        \n",
    "        # compute quaility metrics\n",
    "        metrics_boot = quality_metrics_report(y_test_boot, y_test_pred_boot, y_test_proba_boot)\n",
    "        metrics.append(metrics_boot)\n",
    "        \n",
    "    metrics = np.array(metrics)\n",
    "    df = pd.DataFrame()\n",
    "    df['Metrics'] = columns=['Accuracy', 'Precision', 'Recall', 'F1', 'ROC AUC']\n",
    "    df['Mean']    = metrics.mean(axis=0)\n",
    "    df['Std']     = metrics.std(axis=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Metrics      Mean       Std\n",
      "0   Accuracy  0.792294  0.003665\n",
      "1  Precision  0.804392  0.004556\n",
      "2     Recall  0.897828  0.003922\n",
      "3         F1  0.848536  0.003179\n",
      "4    ROC AUC  0.837551  0.003929\n"
     ]
    }
   ],
   "source": [
    "df = botstrap_uncertainties(logreg, X_test, y_test, iters=100)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Expected output (approximately):\n",
    "\n",
    "<center>   \n",
    "    \n",
    "```python\n",
    "     Metrics      Mean       Std\n",
    "0   Accuracy  0.789478  0.004269\n",
    "1  Precision  0.801227  0.004772\n",
    "2     Recall  0.897766  0.004172\n",
    "3         F1  0.846743  0.003407\n",
    "4    ROC AUC  0.835261  0.004732\n",
    "    \n",
    "``` \n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "85c90a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 2: Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## K-Fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<center><img src=\"img/kfold.png\" width=\"600\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "K-Fold:\n",
    "    \n",
    "1. Split the data into ùêæ folds\n",
    "2. For ùëñ=1,‚Ä¶,ùêæ do: \\\n",
    "    2.1 Keep ùëñ-th fold for validation \\\n",
    "    2.2 Use other ùêæ‚àí1 folds to fit a model \\\n",
    "    2.3 Measure its quality on the validation fold \\\n",
    "3. Estimate mean and standard deviation of the quality metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# define a classifier\n",
    "logreg = LogisticRegression(penalty='l2', C=1.0, max_iter=1000, class_weight=None, solver='lbfgs', random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 2\n",
    "Using K-Fold cross-validation estimate means and standard deviation of the quality metrics for the classifier above. \n",
    "\n",
    "**Hint:** use `sklearn.model_selection.KFold(shuffle=True, random_state=11)` as it is shown in https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html . Use function `quality_metrics_report` above to compute the quality metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ce8dd96b1fbaf6d3ee2fe75526ca245",
     "grade": false,
     "grade_id": "a3e242",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def kfold_uncertainties(model, X, y, n_splits=10):\n",
    "    \n",
    "    metrics = []\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=11)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        \n",
    "        # fit the model on the train subsample, \n",
    "        # get y_test_proba and y_test_pred predictions on the test\n",
    "        logreg.fit(X[train_index], y[train_index])\n",
    "        y_test_pred = logreg.predict(X[test_index])\n",
    "        y_test_proba = logreg.predict_proba(X[test_index])[:, 1]\n",
    "        \n",
    "        # compute quaility metrics\n",
    "        metrics_iter = quality_metrics_report(y[test_index], y_test_pred, y_test_proba)\n",
    "        metrics.append(metrics_iter)\n",
    "        \n",
    "    metrics = np.array(metrics)\n",
    "    df = pd.DataFrame()\n",
    "    df['Metrics'] = columns=['Accuracy', 'Precision', 'Recall', 'F1', 'ROC AUC']\n",
    "    df['Mean']    = metrics.mean(axis=0)\n",
    "    df['Std']     = metrics.std(axis=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Metrics      Mean       Std\n",
      "0   Accuracy  0.790694  0.006743\n",
      "1  Precision  0.802153  0.010757\n",
      "2     Recall  0.898820  0.008051\n",
      "3         F1  0.847678  0.006583\n",
      "4    ROC AUC  0.839133  0.006790\n"
     ]
    }
   ],
   "source": [
    "df_kf = kfold_uncertainties(logreg, X, y, n_splits=10)\n",
    "print(df_kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Expected output:\n",
    "\n",
    "<center>   \n",
    "    \n",
    "```python\n",
    "     Metrics      Mean       Std\n",
    "0   Accuracy  0.790694  0.006743\n",
    "1  Precision  0.802153  0.010757\n",
    "2     Recall  0.898820  0.008051\n",
    "3         F1  0.847678  0.006583\n",
    "4    ROC AUC  0.839133  0.006790\n",
    "    \n",
    "``` \n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "5cf9e8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 3: Statistical model comparison (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hypothesis test\n",
    "\n",
    "<center><img src=\"img/hypo.png\" width=\"600\"></center>\n",
    "\n",
    "We have two hypothesis:\n",
    "* $ùêª_0$: the models have the same quality\n",
    "* $ùêª_1$: the models have the different qualities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Define models we would like to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.790694</td>\n",
       "      <td>0.006743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.802153</td>\n",
       "      <td>0.010757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.898820</td>\n",
       "      <td>0.008051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.847678</td>\n",
       "      <td>0.006583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROC AUC</td>\n",
       "      <td>0.839133</td>\n",
       "      <td>0.006790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Metrics      Mean       Std\n",
       "0   Accuracy  0.790694  0.006743\n",
       "1  Precision  0.802153  0.010757\n",
       "2     Recall  0.898820  0.008051\n",
       "3         F1  0.847678  0.006583\n",
       "4    ROC AUC  0.839133  0.006790"
      ]
     },
     "execution_count": 15,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a model\n",
    "model_1 = LogisticRegression(penalty='l2', C=1.0, max_iter=1000, class_weight=None, solver='lbfgs', random_state=11)\n",
    "\n",
    "# test a model\n",
    "kfold_uncertainties(model_1, X, y, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.790694</td>\n",
       "      <td>0.006743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.802153</td>\n",
       "      <td>0.010757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.898820</td>\n",
       "      <td>0.008051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.847678</td>\n",
       "      <td>0.006583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROC AUC</td>\n",
       "      <td>0.839133</td>\n",
       "      <td>0.006790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Metrics      Mean       Std\n",
       "0   Accuracy  0.790694  0.006743\n",
       "1  Precision  0.802153  0.010757\n",
       "2     Recall  0.898820  0.008051\n",
       "3         F1  0.847678  0.006583\n",
       "4    ROC AUC  0.839133  0.006790"
      ]
     },
     "execution_count": 16,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import kNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# define a model 2\n",
    "model_2 = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "# test a model\n",
    "kfold_uncertainties(model_2, X, y, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# install mlxtend lib\n",
    "# !pip3 install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Dietterich‚Äôs 5x2-Fold CV paired t test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic: -17.720\n",
      "p-value: 0.000\n",
      "The models are significantply different.\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "t, p = paired_ttest_5x2cv(estimator1=model_1,\n",
    "                          estimator2=model_2,\n",
    "                          X=X, y=y,\n",
    "                          random_seed=1)\n",
    "\n",
    "print('t statistic: %.3f' % t)\n",
    "print('p-value: %.3f' % p)\n",
    "\n",
    "if p <= 0.05:\n",
    "    print(\"The models are significantply different.\")\n",
    "else:\n",
    "    print(\"The models are NOT significantply different.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}